{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"},{"sourceId":6060,"sourceType":"modelInstanceVersion","modelInstanceId":4681}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-11T08:24:27.355214Z","iopub.execute_input":"2024-07-11T08:24:27.355455Z","iopub.status.idle":"2024-07-11T08:24:29.041252Z","shell.execute_reply.started":"2024-07-11T08:24:27.355428Z","shell.execute_reply":"2024-07-11T08:24:29.040412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras_nlp\nimport os\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"KerasNLP version:\", keras_nlp.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:24:34.892775Z","iopub.execute_input":"2024-07-11T08:24:34.893279Z","iopub.status.idle":"2024-07-11T08:24:50.605677Z","shell.execute_reply.started":"2024-07-11T08:24:34.893243Z","shell.execute_reply":"2024-07-11T08:24:50.604669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ntry:\n\n    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n    \n\n    strategy = tf.distribute.TPUStrategy(tpu_resolver)\nexcept ValueError:\n    print(\"TPU not activated. Falling back to MirroredStrategy for CPU/GPU.\")\n    strategy = tf.distribute.MirroredStrategy()\n\nprint(\"Replicas:\", strategy.num_replicas_in_sync)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:27:23.645945Z","iopub.execute_input":"2024-07-11T08:27:23.646373Z","iopub.status.idle":"2024-07-11T08:27:32.500000Z","shell.execute_reply.started":"2024-07-11T08:27:23.646342Z","shell.execute_reply":"2024-07-11T08:27:32.499050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/contradictory-my-dear-watson/'\n\nRESULT_DICT = {\n    0 : \"entailment\",\n    1 : \"neutral\",\n    2 : \"contradiction\"\n}\n\nfor dirname, _, filenames in os.walk(DATA_DIR):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:27:51.262735Z","iopub.execute_input":"2024-07-11T08:27:51.263758Z","iopub.status.idle":"2024-07-11T08:27:51.269736Z","shell.execute_reply.started":"2024-07-11T08:27:51.263721Z","shell.execute_reply":"2024-07-11T08:27:51.268878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(DATA_DIR + \"train.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:27:54.977674Z","iopub.execute_input":"2024-07-11T08:27:54.978121Z","iopub.status.idle":"2024-07-11T08:27:55.156840Z","shell.execute_reply.started":"2024-07-11T08:27:54.978084Z","shell.execute_reply":"2024-07-11T08:27:55.155765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(DATA_DIR + \"test.csv\")\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:00.967168Z","iopub.execute_input":"2024-07-11T08:28:00.968064Z","iopub.status.idle":"2024-07-11T08:28:01.044843Z","shell.execute_reply.started":"2024-07-11T08:28:00.968023Z","shell.execute_reply":"2024-07-11T08:28:01.043878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_pair_of_sentence(x):\n    print( \"Premise : \" + x['premise'])\n    print( \"Hypothesis: \" + x['hypothesis'])\n    print( \"Language: \" + x['language'])\n    print( \"Label: \" + str(x['label']))\n    print()\n\ndf_train.head(10).apply(lambda x : display_pair_of_sentence(x), axis=1)\n\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:04.161947Z","iopub.execute_input":"2024-07-11T08:28:04.162837Z","iopub.status.idle":"2024-07-11T08:28:04.172037Z","shell.execute_reply.started":"2024-07-11T08:28:04.162799Z","shell.execute_reply":"2024-07-11T08:28:04.171093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(12, 4))\n\n# Plot the total crashes\nsns.set_color_codes(\"pastel\")\nsns.despine()\nax = sns.countplot(data=df_train, \n                   y=\"label\",\n                   order = df_train['label'].value_counts().index)\n\nabs_values = df_train['label'].value_counts(ascending=False)\nrel_values = df_train['label'].value_counts(ascending=False, normalize=True).values * 100\nlbls = [f'{p[0]} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n\nax.bar_label(container=ax.containers[0], labels=lbls)\n\nax.set_yticklabels([RESULT_DICT[index] for index in abs_values.index])\n\nax.set_title(\"Distribution of labels in the training set\")","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:31.472943Z","iopub.execute_input":"2024-07-11T08:28:31.473322Z","iopub.status.idle":"2024-07-11T08:28:31.696646Z","shell.execute_reply.started":"2024-07-11T08:28:31.473295Z","shell.execute_reply":"2024-07-11T08:28:31.695734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 10))\n\n# Plot the total crashes\nsns.set_color_codes(\"pastel\")\nsns.despine()\nax = sns.countplot(data=df_train, \n                   y=\"language\",\n                   order = df_train['language'].value_counts().index)\n\nabs_values = df_train['language'].value_counts(ascending=False)\nrel_values = df_train['language'].value_counts(ascending=False, normalize=True).values * 100\nlbls = [f'{p[0]} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n\nax.bar_label(container=ax.containers[0], labels=lbls)\n\nax.set_title(\"Distribution of languages in the training set\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:39.694747Z","iopub.execute_input":"2024-07-11T08:28:39.695141Z","iopub.status.idle":"2024-07-11T08:28:40.026643Z","shell.execute_reply.started":"2024-07-11T08:28:39.695110Z","shell.execute_reply":"2024-07-11T08:28:40.025683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"premise_length\"] = df_train[\"premise\"].apply(lambda x : len(x))\ndf_train[\"hypothesis_length\"] = df_train[\"hypothesis\"].apply(lambda x : len(x))\ndf_train[[\"hypothesis_length\", \"premise_length\"]].describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:44.745864Z","iopub.execute_input":"2024-07-11T08:28:44.746261Z","iopub.status.idle":"2024-07-11T08:28:44.774352Z","shell.execute_reply.started":"2024-07-11T08:28:44.746231Z","shell.execute_reply":"2024-07-11T08:28:44.773257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VALIDATION_SPLIT = 0.3\nTRAIN_SIZE = int(df_train.shape[0]*(1-VALIDATION_SPLIT))\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:50.006390Z","iopub.execute_input":"2024-07-11T08:28:50.006768Z","iopub.status.idle":"2024-07-11T08:28:50.011702Z","shell.execute_reply.started":"2024-07-11T08:28:50.006736Z","shell.execute_reply":"2024-07-11T08:28:50.010724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_labels(x, y):\n    return (x[0], x[1]), y\n\n\ntraining_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            df_train[['premise','hypothesis']].values,\n            keras.utils.to_categorical(df_train['label'], num_classes=3)\n        )\n    )\n)\n\ntrain_dataset = training_dataset.take(TRAIN_SIZE)\nval_dataset = training_dataset.skip(TRAIN_SIZE)\n\n# Apply the preprocessor to every sample of train, val and test data using `map()`.\n# [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data/AUTOTUNE) and `prefetch()` are options to tune performance, see\n# https://www.tensorflow.org/guide/data_performance for details.\n\ntrain_preprocessed = train_dataset.map(split_labels, tf.data.AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\nval_preprocessed = val_dataset.map(split_labels, tf.data.AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:28:53.468934Z","iopub.execute_input":"2024-07-11T08:28:53.469294Z","iopub.status.idle":"2024-07-11T08:28:53.557770Z","shell.execute_reply.started":"2024-07-11T08:28:53.469265Z","shell.execute_reply":"2024-07-11T08:28:53.556847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a BERT model.\n\nwith strategy.scope():\n    classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_base_multi\", num_classes=3)\n\n    # in distributed training, the recommendation is to scale batch size and learning rate with the numer of workers.\n    classifier.compile(optimizer=keras.optimizers.Adam(1e-5*strategy.num_replicas_in_sync),\n                       loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n                       metrics=['accuracy'])\n    \n    classifier.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:29:01.278209Z","iopub.execute_input":"2024-07-11T08:29:01.278596Z","iopub.status.idle":"2024-07-11T08:30:13.177435Z","shell.execute_reply.started":"2024-07-11T08:29:01.278565Z","shell.execute_reply":"2024-07-11T08:30:13.176260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS=3\nhistory = classifier.fit(train_preprocessed,\n                         epochs=EPOCHS,\n                         validation_data=val_preprocessed\n                        )","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:30:39.926556Z","iopub.execute_input":"2024-07-11T08:30:39.926969Z","iopub.status.idle":"2024-07-11T08:33:44.221513Z","shell.execute_reply.started":"2024-07-11T08:30:39.926906Z","shell.execute_reply":"2024-07-11T08:33:44.220168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = classifier.predict((df_test['premise'],df_test['hypothesis']), batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:34:14.844997Z","iopub.execute_input":"2024-07-11T08:34:14.845832Z","iopub.status.idle":"2024-07-11T08:34:32.924798Z","shell.execute_reply.started":"2024-07-11T08:34:14.845791Z","shell.execute_reply":"2024-07-11T08:34:32.923892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = df_test.id.copy().to_frame()\nsubmission[\"prediction\"] = np.argmax(predictions, axis=1)\n\nsubmission","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:35:26.691244Z","iopub.execute_input":"2024-07-11T08:35:26.691617Z","iopub.status.idle":"2024-07-11T08:35:26.703869Z","shell.execute_reply.started":"2024-07-11T08:35:26.691587Z","shell.execute_reply":"2024-07-11T08:35:26.703033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T08:35:31.409744Z","iopub.execute_input":"2024-07-11T08:35:31.410645Z","iopub.status.idle":"2024-07-11T08:35:31.421268Z","shell.execute_reply.started":"2024-07-11T08:35:31.410601Z","shell.execute_reply":"2024-07-11T08:35:31.420548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}