{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43ca380",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-25T16:35:51.691289Z",
     "iopub.status.busy": "2024-07-25T16:35:51.690370Z",
     "iopub.status.idle": "2024-07-25T16:35:52.428052Z",
     "shell.execute_reply": "2024-07-25T16:35:52.427090Z"
    },
    "papermill": {
     "duration": 0.746077,
     "end_time": "2024-07-25T16:35:52.430168",
     "exception": false,
     "start_time": "2024-07-25T16:35:51.684091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81870f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:35:52.440176Z",
     "iopub.status.busy": "2024-07-25T16:35:52.439817Z",
     "iopub.status.idle": "2024-07-25T16:36:04.947310Z",
     "shell.execute_reply": "2024-07-25T16:36:04.946523Z"
    },
    "papermill": {
     "duration": 12.514973,
     "end_time": "2024-07-25T16:36:04.949697",
     "exception": false,
     "start_time": "2024-07-25T16:35:52.434724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 16:35:54.113647: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 16:35:54.113789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 16:35:54.245697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04db7c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:04.959940Z",
     "iopub.status.busy": "2024-07-25T16:36:04.959407Z",
     "iopub.status.idle": "2024-07-25T16:36:04.987538Z",
     "shell.execute_reply": "2024-07-25T16:36:04.986717Z"
    },
    "papermill": {
     "duration": 0.035436,
     "end_time": "2024-07-25T16:36:04.989653",
     "exception": false,
     "start_time": "2024-07-25T16:36:04.954217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459770ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:04.999703Z",
     "iopub.status.busy": "2024-07-25T16:36:04.999140Z",
     "iopub.status.idle": "2024-07-25T16:36:05.011975Z",
     "shell.execute_reply": "2024-07-25T16:36:05.011142Z"
    },
    "papermill": {
     "duration": 0.019803,
     "end_time": "2024-07-25T16:36:05.013948",
     "exception": false,
     "start_time": "2024-07-25T16:36:04.994145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff54d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:05.023885Z",
     "iopub.status.busy": "2024-07-25T16:36:05.023597Z",
     "iopub.status.idle": "2024-07-25T16:36:05.055014Z",
     "shell.execute_reply": "2024-07-25T16:36:05.054178Z"
    },
    "papermill": {
     "duration": 0.038526,
     "end_time": "2024-07-25T16:36:05.056977",
     "exception": false,
     "start_time": "2024-07-25T16:36:05.018451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_number</th>\n",
       "      <th>Ticket_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund Mr Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen Mr William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                              Name     Sex   Age  SibSp  \\\n",
       "0                            Braund Mr Owen Harris    male  22.0      1   \n",
       "1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n",
       "2                             Heikkinen Miss Laina  female  26.0      0   \n",
       "3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n",
       "4                           Allen Mr William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n",
       "0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n",
       "1      0          PC 17599  71.2833   C85        C         17599          PC  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n",
       "3      0            113803  53.1000  C123        S        113803        NONE  \n",
       "4      0            373450   8.0500   NaN        S        373450        NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "    \n",
    "    def ticket_number(x):\n",
    "        return x.split(\" \")[-1]\n",
    "        \n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "    \n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n",
    "    return df\n",
    "    \n",
    "preprocessed_train = preprocess(train)\n",
    "preprocessed_test = preprocess(test)\n",
    "\n",
    "preprocessed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e507965e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:05.067477Z",
     "iopub.status.busy": "2024-07-25T16:36:05.067150Z",
     "iopub.status.idle": "2024-07-25T16:36:05.072328Z",
     "shell.execute_reply": "2024-07-25T16:36:05.071428Z"
    },
    "papermill": {
     "duration": 0.012623,
     "end_time": "2024-07-25T16:36:05.074294",
     "exception": false,
     "start_time": "2024-07-25T16:36:05.061671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n"
     ]
    }
   ],
   "source": [
    "input_features = list(preprocessed_train.columns)\n",
    "input_features.remove(\"Ticket\")\n",
    "input_features.remove(\"PassengerId\")\n",
    "input_features.remove(\"Survived\")\n",
    "\n",
    "\n",
    "print(f\"Input features: {input_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3844ec61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:05.084891Z",
     "iopub.status.busy": "2024-07-25T16:36:05.084624Z",
     "iopub.status.idle": "2024-07-25T16:36:06.136812Z",
     "shell.execute_reply": "2024-07-25T16:36:06.135829Z"
    },
    "papermill": {
     "duration": 1.060127,
     "end_time": "2024-07-25T16:36:06.139197",
     "exception": false,
     "start_time": "2024-07-25T16:36:05.079070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_names(features, labels=None):\n",
    "    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n",
    "    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n",
    "    return features, labels\n",
    "\n",
    "train_token = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train,label=\"Survived\").map(tokenize_names)\n",
    "test_token = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_test).map(tokenize_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2d7db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:06.150342Z",
     "iopub.status.busy": "2024-07-25T16:36:06.150020Z",
     "iopub.status.idle": "2024-07-25T16:36:19.702768Z",
     "shell.execute_reply": "2024-07-25T16:36:19.701735Z"
    },
    "papermill": {
     "duration": 13.560607,
     "end_time": "2024-07-25T16:36:19.704885",
     "exception": false,
     "start_time": "2024-07-25T16:36:06.144278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-07-25 16:36:06.1762 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-25 16:36:06.1771 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-25 16:36:06.1772 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-07-25 16:36:12.7861 UTC kernel.cc:1233] Loading model from path /tmp/tmpfaa3qyho/model/ with prefix bfab7018db534dde\n",
      "[INFO 24-07-25 16:36:12.7918 UTC quick_scorer_extended.cc:903] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "[INFO 24-07-25 16:36:12.7922 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 24-07-25 16:36:12.7922 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8260869383811951 Loss:0.8608942627906799\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose=0, # Very few logs\n",
    "    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "    exclude_non_specified_features=True, # Only use the features in \"features\"\n",
    "    random_seed=1234,\n",
    ")\n",
    "model.fit(train_token)\n",
    "\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b15ed39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:19.716366Z",
     "iopub.status.busy": "2024-07-25T16:36:19.716072Z",
     "iopub.status.idle": "2024-07-25T16:36:20.770188Z",
     "shell.execute_reply": "2024-07-25T16:36:20.769000Z"
    },
    "papermill": {
     "duration": 1.062167,
     "end_time": "2024-07-25T16:36:20.772320",
     "exception": false,
     "start_time": "2024-07-25T16:36:19.710153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-07-25 16:36:19.7286 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-25 16:36:19.7286 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-25 16:36:19.7286 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-07-25 16:36:20.4711 UTC kernel.cc:1233] Loading model from path /tmp/tmpt18uif63/model/ with prefix 6f27d0282bcf471b\n",
      "[INFO 24-07-25 16:36:20.4792 UTC decision_forest.cc:660] Model loaded with 40 root(s), 2106 node(s), and 10 input feature(s).\n",
      "[INFO 24-07-25 16:36:20.4793 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782608687877655 Loss:1.0586705207824707\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose=0, \n",
    "    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "    exclude_non_specified_features=True, \n",
    "     \n",
    "    min_examples=1,\n",
    "    categorical_algorithm=\"RANDOM\",\n",
    "    #max_depth=4,\n",
    "    shrinkage=0.05,\n",
    "    #num_candidate_attributes_ratio=0.2,\n",
    "    split_axis=\"SPARSE_OBLIQUE\",\n",
    "    sparse_oblique_normalization=\"MIN_MAX\",\n",
    "    sparse_oblique_num_projections_exponent=2.0,\n",
    "    num_trees=2000,\n",
    "    #validation_ratio=0.0,\n",
    "    random_seed=1234,\n",
    "    \n",
    ")\n",
    "model.fit(train_token)\n",
    "\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f54da50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:20.784340Z",
     "iopub.status.busy": "2024-07-25T16:36:20.784009Z",
     "iopub.status.idle": "2024-07-25T16:36:20.797245Z",
     "shell.execute_reply": "2024-07-25T16:36:20.796220Z"
    },
    "papermill": {
     "duration": 0.024091,
     "end_time": "2024-07-25T16:36:20.801791",
     "exception": false,
     "start_time": "2024-07-25T16:36:20.777700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (11):\n",
      "\tAge\n",
      "\tCabin\n",
      "\tEmbarked\n",
      "\tFare\n",
      "\tName\n",
      "\tParch\n",
      "\tPclass\n",
      "\tSex\n",
      "\tSibSp\n",
      "\tTicket_item\n",
      "\tTicket_number\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.           \"Sex\"  0.585997 ################\n",
      "    2.           \"Age\"  0.364636 #######\n",
      "    3.          \"Fare\"  0.266191 ###\n",
      "    4.          \"Name\"  0.207054 #\n",
      "    5.        \"Pclass\"  0.179191 \n",
      "    6. \"Ticket_number\"  0.178806 \n",
      "    7.      \"Embarked\"  0.177803 \n",
      "    8.   \"Ticket_item\"  0.177009 \n",
      "    9.         \"Parch\"  0.175276 \n",
      "   10.         \"SibSp\"  0.171694 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.  \"Sex\" 34.000000 ################\n",
      "    2. \"Name\"  6.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.           \"Age\" 510.000000 ################\n",
      "    2.          \"Fare\" 298.000000 #########\n",
      "    3.          \"Name\" 60.000000 #\n",
      "    4.   \"Ticket_item\" 47.000000 #\n",
      "    5.           \"Sex\" 40.000000 #\n",
      "    6.         \"Parch\" 22.000000 \n",
      "    7. \"Ticket_number\" 20.000000 \n",
      "    8.      \"Embarked\" 15.000000 \n",
      "    9.        \"Pclass\" 15.000000 \n",
      "   10.         \"SibSp\"  6.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.           \"Sex\" 482.453470 ################\n",
      "    2.           \"Age\" 390.670218 ############\n",
      "    3.          \"Fare\" 321.170935 ##########\n",
      "    4.          \"Name\" 102.043860 ###\n",
      "    5.        \"Pclass\" 26.605919 \n",
      "    6.   \"Ticket_item\" 22.954813 \n",
      "    7. \"Ticket_number\" 17.413948 \n",
      "    8.      \"Embarked\"  8.969861 \n",
      "    9.         \"Parch\"  6.947528 \n",
      "   10.         \"SibSp\"  0.455899 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 1.05867\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 40\n",
      "Total number of nodes: 2106\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 40 Average: 52.65 StdDev: 4.2869\n",
      "Min: 41 Max: 61 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 41, 42)  2   5.00%   5.00% ##\n",
      "[ 42, 43)  0   0.00%   5.00%\n",
      "[ 43, 44)  0   0.00%   5.00%\n",
      "[ 44, 45)  0   0.00%   5.00%\n",
      "[ 45, 46)  0   0.00%   5.00%\n",
      "[ 46, 47)  0   0.00%   5.00%\n",
      "[ 47, 48)  4  10.00%  15.00% ####\n",
      "[ 48, 49)  0   0.00%  15.00%\n",
      "[ 49, 50)  3   7.50%  22.50% ###\n",
      "[ 50, 51)  0   0.00%  22.50%\n",
      "[ 51, 52)  4  10.00%  32.50% ####\n",
      "[ 52, 53)  0   0.00%  32.50%\n",
      "[ 53, 54) 11  27.50%  60.00% ##########\n",
      "[ 54, 55)  0   0.00%  60.00%\n",
      "[ 55, 56) 10  25.00%  85.00% #########\n",
      "[ 56, 57)  0   0.00%  85.00%\n",
      "[ 57, 58)  2   5.00%  90.00% ##\n",
      "[ 58, 59)  0   0.00%  90.00%\n",
      "[ 59, 60)  3   7.50%  97.50% ###\n",
      "[ 60, 61]  1   2.50% 100.00% #\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1073 Average: 4.84623 StdDev: 0.454477\n",
      "Min: 2 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 2, 3)   1   0.09%   0.09%\n",
      "[ 3, 4)  38   3.54%   3.63%\n",
      "[ 4, 5)  86   8.01%  11.65% #\n",
      "[ 5, 5] 948  88.35% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1073 Average: 29.7856 StdDev: 71.8675\n",
      "Min: 1 Max: 458 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   1,  23) 846  78.84%  78.84% ##########\n",
      "[  23,  46)  62   5.78%  84.62% #\n",
      "[  46,  69)  48   4.47%  89.10% #\n",
      "[  69,  92)  21   1.96%  91.05%\n",
      "[  92, 115)  10   0.93%  91.99%\n",
      "[ 115, 138)  15   1.40%  93.38%\n",
      "[ 138, 161)  23   2.14%  95.53%\n",
      "[ 161, 184)   6   0.56%  96.09%\n",
      "[ 184, 207)   3   0.28%  96.37%\n",
      "[ 207, 230)   4   0.37%  96.74%\n",
      "[ 230, 252)   1   0.09%  96.83%\n",
      "[ 252, 275)   1   0.09%  96.92%\n",
      "[ 275, 298)   2   0.19%  97.11%\n",
      "[ 298, 321)   2   0.19%  97.30%\n",
      "[ 321, 344)   0   0.00%  97.30%\n",
      "[ 344, 367)   9   0.84%  98.14%\n",
      "[ 367, 390)   6   0.56%  98.70%\n",
      "[ 390, 413)   9   0.84%  99.53%\n",
      "[ 413, 436)   4   0.37%  99.91%\n",
      "[ 436, 458]   1   0.09% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t510 : Age [NUMERICAL]\n",
      "\t298 : Fare [NUMERICAL]\n",
      "\t60 : Name [CATEGORICAL_SET]\n",
      "\t47 : Ticket_item [CATEGORICAL]\n",
      "\t40 : Sex [CATEGORICAL]\n",
      "\t22 : Parch [NUMERICAL]\n",
      "\t20 : Ticket_number [CATEGORICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t15 : Embarked [CATEGORICAL]\n",
      "\t6 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t6 : Name [CATEGORICAL_SET]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t48 : Age [NUMERICAL]\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t25 : Fare [NUMERICAL]\n",
      "\t6 : Name [CATEGORICAL_SET]\n",
      "\t5 : Pclass [NUMERICAL]\n",
      "\t2 : Ticket_number [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t121 : Age [NUMERICAL]\n",
      "\t74 : Fare [NUMERICAL]\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t19 : Name [CATEGORICAL_SET]\n",
      "\t8 : Ticket_number [CATEGORICAL]\n",
      "\t8 : Embarked [CATEGORICAL]\n",
      "\t6 : Pclass [NUMERICAL]\n",
      "\t6 : Parch [NUMERICAL]\n",
      "\t3 : Ticket_item [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t261 : Age [NUMERICAL]\n",
      "\t164 : Fare [NUMERICAL]\n",
      "\t36 : Sex [CATEGORICAL]\n",
      "\t35 : Name [CATEGORICAL_SET]\n",
      "\t16 : Ticket_item [CATEGORICAL]\n",
      "\t13 : Ticket_number [CATEGORICAL]\n",
      "\t12 : Embarked [CATEGORICAL]\n",
      "\t11 : Parch [NUMERICAL]\n",
      "\t9 : Pclass [NUMERICAL]\n",
      "\t2 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t510 : Age [NUMERICAL]\n",
      "\t298 : Fare [NUMERICAL]\n",
      "\t60 : Name [CATEGORICAL_SET]\n",
      "\t47 : Ticket_item [CATEGORICAL]\n",
      "\t40 : Sex [CATEGORICAL]\n",
      "\t22 : Parch [NUMERICAL]\n",
      "\t20 : Ticket_number [CATEGORICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t15 : Embarked [CATEGORICAL]\n",
      "\t6 : SibSp [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t851 : ObliqueCondition\n",
      "\t135 : ContainsBitmapCondition\n",
      "\t47 : ContainsCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t38 : ContainsBitmapCondition\n",
      "\t2 : ContainsCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t78 : ObliqueCondition\n",
      "\t40 : ContainsBitmapCondition\n",
      "\t2 : ContainsCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t207 : ObliqueCondition\n",
      "\t58 : ContainsBitmapCondition\n",
      "\t14 : ContainsCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t447 : ObliqueCondition\n",
      "\t83 : ContainsBitmapCondition\n",
      "\t29 : ContainsCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t851 : ObliqueCondition\n",
      "\t135 : ContainsBitmapCondition\n",
      "\t47 : ContainsCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 40\n",
      "\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n",
      "\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n",
      "\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n",
      "\tIter:26 train-loss:0.647960 valid-loss:1.065191  train-accuracy:0.922403 valid-accuracy:0.782609\n",
      "\tIter:36 train-loss:0.557737 valid-loss:1.071260  train-accuracy:0.922403 valid-accuracy:0.782609\n",
      "\tIter:46 train-loss:0.494259 valid-loss:1.063639  train-accuracy:0.927409 valid-accuracy:0.771739\n",
      "\tIter:56 train-loss:0.443537 valid-loss:1.070069  train-accuracy:0.939925 valid-accuracy:0.760870\n",
      "\tIter:66 train-loss:0.404514 valid-loss:1.081874  train-accuracy:0.949937 valid-accuracy:0.760870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060605b",
   "metadata": {
    "papermill": {
     "duration": 0.006152,
     "end_time": "2024-07-25T16:36:20.814545",
     "exception": false,
     "start_time": "2024-07-25T16:36:20.808393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3c6233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:36:20.828043Z",
     "iopub.status.busy": "2024-07-25T16:36:20.827720Z",
     "iopub.status.idle": "2024-07-25T16:36:22.031128Z",
     "shell.execute_reply": "2024-07-25T16:36:22.029918Z"
    },
    "papermill": {
     "duration": 1.213049,
     "end_time": "2024-07-25T16:36:22.033683",
     "exception": false,
     "start_time": "2024-07-25T16:36:20.820634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission exported to /kaggle/working/submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,0\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "def prediction_to_kaggle_format(model, threshold=0.5):\n",
    "    proba_survive = model.predict(test_token, verbose=0)[:,0]\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive >= threshold).astype(int)\n",
    "    })\n",
    "\n",
    "def make_submission(kaggle_predictions):\n",
    "    path=\"/kaggle/working/submission.csv\"\n",
    "    kaggle_predictions.to_csv(path, index=False)\n",
    "    print(f\"Submission exported to {path}\")\n",
    "    \n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "make_submission(kaggle_predictions)\n",
    "!head /kaggle/working/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da34a01",
   "metadata": {
    "papermill": {
     "duration": 0.006427,
     "end_time": "2024-07-25T16:36:22.047333",
     "exception": false,
     "start_time": "2024-07-25T16:36:22.040906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.244872,
   "end_time": "2024-07-25T16:36:25.055381",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-25T16:35:48.810509",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
